---
title: "Fishery definition for YFT in dolphin sets - Catch weighted"
author: "Haikun Xu"
date: "`r Sys.Date()`"
output: word_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      fig.height = 8,
                      fig.width = 12)
```

```{r load raw data and library}
library(FishFreqClustering)
library(FishFreqTree)
library(tidyverse)

directory <- "D:/OneDrive - IATTC/IATTC/2024/Irregular clustering/YFT DEL/"
setwd(directory)

Raw <- read.csv("yft_lf_2000_to_2022.csv")
Raw$quarter = ceiling(Raw$month / 3)
Raw$lat = Raw$lat.5deg + 2.5
Raw$lon = Raw$lon.5deg - 2.5
```

```{r prepare the dataset for the clustering analysis}
LF.DEL <- Raw %>% filter(class == 6, setype == 1) # 1=DEL; 4=NOA; 5=OBJ
LF <- LF.DEL[, c("year", "quarter", "lat", "lon", paste0("X", 1:201))] %>%
  group_by(lat, lon) %>%
  mutate(N = length(unique(paste0(year, "-", quarter)))) %>%
  filter(N > 3, lat > -10) # remove the cells with less than 4 quarters of data since 2000

bins <- seq(1, 201, 1) # data length bins
new_bins <- seq(50, 180, 10) # bins to be used in the clustering analysis

# first aggregate the raw LF to the new bins by quarter
LF1 <-
  lf.aggregate(
    LF,
    fcol = 5,
    lcol = 205,
    bins,
    new_bins,
    LengthOnly = FALSE
  )

# Chekcing the data by making two plots
bins <- new_bins # use the new bins
nbins <- length(bins)
fcol = 5
lcol = 4 + length(bins)
save_dir=directory

make.meanl.map(LF1,fcol,lcol,bins,save_dir,width=10,height=10)
make.lf.map(LF1,fcol,lcol,bins,save_dir)

# divide the LF by the mean LF for the year-quarter
LF2 <- lf.demean(LF1, fcol, lcol, bins)
```

```{r catch}
cae <- BSE::read.cae.f("D:/OneDrive - IATTC/IATTC/2024/SAC15/PS Database/", "CAE-LatLon2000-2023.txt",2000,2023)

YFT_DEL_catch <- cae %>%
  filter(setype == 1, class == 6) %>%
  rename(lat = latc5, lon = lonc5) %>%
  group_by(lat, lon) %>%
  summarise(Catch = sum(sum.trop.tunas)/1000)

wmap <- map_data("world")
ggplot(data = YFT_DEL_catch) +
  geom_tile(aes(x = lon, y = lat, fill = Catch), color = "black") +
    scale_fill_gradient(
    low = "white",
    high = "red",
    na.value = "white",
    limits = c(0, max(YFT_DEL_catch$Catch))
  ) +
  geom_polygon(
    data = wmap,
    aes(long, lat, group = group),
    fill = "black",
    colour = "white",
    lwd = 0.5
  ) +
  coord_quickmap(ylim = c(min(YFT_DEL_catch$lat), max(YFT_DEL_catch$lat)), xlim = c(min(YFT_DEL_catch$lon), max(YFT_DEL_catch$lon))) +
  theme_bw()
```

```{r}
mmd <- LF2[,c(2,4:(lcol+1))] # mmd is the input data for the clustering analysis - it should have year, lat, lon, and bin numbers

# setting up input data frames for clustering algorithm
temp = packbylatlon(mmd, 5, 5, nbins)  # aggregate the input LF across time for each grid cell
packedmmd3 = temp$table1
packedpdf3 = topdf(packedmmd3, 4, 3 + nbins)
# packedcdf3 = tocdf(packedpdf3, 4, 3 + nbins)
mmdt = packedmmd3[packedmmd3[, 4 + nbins] > 0,]
rrs = mmdt[, 4 + nbins] # sample size
mmdtpdf = packedpdf3[packedmmd3[, 4 + nbins] > 0,] # PDF sums to 1 for each grid
mmdtpdf[, 4 + nbins] = mmdt[, 4 + nbins]
# mmdtcdf = packedcdf3[packedmmd3[, 4 + nbins] > 0,]
# mmdtcdf[, 4 + nbins] = mmdt[, 4 + nbins]

densmatx = matrix(0, nrow(mmdt), nbins)
densmaty = matrix(0, nrow(mmdt), nbins)
for (i in 1:nrow(mmdt)) {
  weightvec = t(mmdtpdf[i, 4:(3 + nbins)])
  # weightvec = weightvec / sum(weightvec)
  densmatx[i, ] = bins / 100
  densmaty[i, ] = t(weightvec)
}

names(mmdtpdf)[2:3] <- c("lat", "lon")
mmdtpdf$Number <- 1:nrow(mmdtpdf)
mmdfpdf_catch <- left_join(mmdtpdf, YFT_DEL_catch)

# check grid ID
ggplot(data = mmdfpdf_catch) +
  geom_text(aes(x = lon, y = lat, label = Number), color = "black") +
  geom_polygon(
    data = wmap,
    aes(long, lat, group = group),
    fill = "black",
    colour = "white",
    lwd = 0.5
  ) +
  coord_quickmap(ylim = c(min(mmdfpdf_catch$lat), max(mmdfpdf_catch$lat)), xlim = c(min(mmdfpdf_catch$lon), max(mmdfpdf_catch$lon))) +
  ggtitle("Grid ID") +
  theme_bw()

# run distributional clustering with adjacency criterion
adjmat <- adjinf(mmdtpdf[, 2], mmdtpdf[, 3], mindist = 5 * sqrt(2)) # the matrix specifying adjacency 
adjmat[16,29] <- 0
adjmat[29,16] <- 0

alydens.spatial23 <-
  hclust.regionsmm(
    as.matrix(densmaty),
    adj = TRUE, # adjacent areas
    adjmat = adjmat,
    rr = mmdfpdf_catch$Catch # rr is the weighting factor; equal weighting is used in this case
  )

# Look at the tree structure
cplotu(alydens.spatial23$merges, alydens.spatial23$distseq, hopt = 'dist')
```

```{r distant matrix}
distantmat <- alydens.spatial23$distantmat
write.csv(distantmat, file = "distantmax.csv", row.names = FALSE)

for (i in 2:nrow(distantmat)) {
  for (j in 1:(i - 1)) {
    distantmat[i, j] <- distantmat[j, i] 
  }
}

# you want to check the distance between, for example [12.5, -112.5], and other grids
Lat <- 2.5
Lon <- -112.5

n <- which(mmdt[,2] == Lat & mmdt[,3] == Lon) # find the grid ID of [2.5, -132.5]
dist <- cbind(distantmat[,n], mmdt[, 2:3])
dist[n,1] <- NA
names(dist) <- c("MJS", "lat", "lon")

wmap <- map_data("world")
ggplot(data = dist) +
  geom_tile(aes(x = lon, y = lat, fill = MJS), color = "black") +
  scale_fill_gradient(
    low = "white",
    high = "red",
    na.value = "white",
    limits = c(0, max(dist$MJS))
  ) +
  geom_point(
    aes(x = -112.5, y = 2.5),
    color = "blue",
    size = 5,
    shape = 13
  ) +
  geom_text(aes(x = lon, y = lat, label = round(MJS,0)), color = "blue") +
  geom_polygon(
    data = wmap,
    aes(long, lat, group = group),
    fill = "black",
    colour = "white",
    lwd = 0.5
  ) +
  coord_quickmap(ylim = c(min(dist$lat), max(dist$lat)), xlim = c(min(dist$lon), max(dist$lon))) +
  theme_bw() +
  ggtitle(paste0("Distance map for ", Lat, "N and ", -Lon, "W"))
ggsave(file = paste0(save_dir, "Distance_map(", Lat, Lon, ").png"), h = 4, w = 6)
```

```{r 3 areas}
# making maps of the clusters and corresponding L-F density curves

#     kk is the number of clusters to use
kk = 3
# save clustering results
temp <- putcolor(alydens.spatial23$merges, kk)
cluster <- cbind(mmdt[,2:3], factor(temp-1), rrs)
names(cluster) <- c("lat", "lon", "cell", "Nsamp")
write.csv(cluster, file = paste0(save_dir, "cluster_YFT", kk, ".csv"), row.names = FALSE)

# # map of clusters
ggplot(data = cluster) +
  geom_tile(aes(x = lon, y = lat, fill = cell), color = "black") +
  geom_polygon(
    data = wmap,
    aes(long, lat, group = group),
    fill = "black",
    colour = "white",
    lwd = 0.5
  ) +
  geom_text(aes(x = lon, y = lat, label = round(Catch)), color = "white", size = 7, data = mmdfpdf_catch) +
  coord_quickmap(ylim = c(min(cluster$lat), max(cluster$lat)),
                 xlim = c(min(cluster$lon), max(cluster$lon))) +
  theme_bw()
ggsave(file = paste0(save_dir, "Clustering_map", kk, ".png"))

# mean LF in each area
LF1_cluster <- left_join(LF1, cluster) %>% rename(Flag = cell)
make.lf.cell(LF1_cluster, fcol, lcol, bins, save_dir, plot_name = paste0("NewLF", kk))
```

```{r 4 areas}
# making maps of the clusters and corresponding L-F density curves

#     kk is the number of clusters to use
kk = 4
# save clustering results
temp <- putcolor(alydens.spatial23$merges, kk)
cluster <- cbind(mmdt[,2:3], factor(temp-1), rrs)
names(cluster) <- c("lat", "lon", "cell", "Nsamp")
write.csv(cluster, file = paste0(save_dir, "cluster_YFT", kk, ".csv"), row.names = FALSE)

# # map of clusters
wmap <- map_data("world")
ggplot(data = cluster) +
  geom_tile(aes(x = lon, y = lat, fill = cell), color = "black") +
  geom_polygon(
    data = wmap,
    aes(long, lat, group = group),
    fill = "black",
    colour = "white",
    lwd = 0.5
  ) +
  geom_text(aes(x = lon, y = lat, label = round(Catch)), color = "white", size = 7, data = mmdfpdf_catch) +
  coord_quickmap(ylim = c(min(cluster$lat), max(cluster$lat)),
                 xlim = c(min(cluster$lon), max(cluster$lon))) +
  theme_bw()
ggsave(file = paste0(save_dir, "Clustering_map", kk, ".png"))

# mean LF in each area
LF1_cluster <- left_join(LF1, cluster) %>% rename(Flag = cell)
make.lf.cell(LF1_cluster, fcol, lcol, bins, save_dir, plot_name = paste0("NewLF", kk))
```

```{r 5 areas}
# making maps of the clusters and corresponding L-F density curves

#     kk is the number of clusters to use
kk = 5
# save clustering results
temp <- putcolor(alydens.spatial23$merges, kk)
cluster <- cbind(mmdt[,2:3], factor(temp-1), rrs)
names(cluster) <- c("lat", "lon", "cell", "Nsamp")
write.csv(cluster, file = paste0(save_dir, "cluster_YFT", kk, ".csv"), row.names = FALSE)

# # map of clusters
wmap <- map_data("world")
ggplot(data = cluster) +
  geom_tile(aes(x = lon, y = lat, fill = cell), color = "black") +
  geom_polygon(
    data = wmap,
    aes(long, lat, group = group),
    fill = "black",
    colour = "white",
    lwd = 0.5
  ) +
  geom_text(aes(x = lon, y = lat, label = round(Catch)), color = "white", size = 7, data = mmdfpdf_catch) +
  coord_quickmap(ylim = c(min(cluster$lat), max(cluster$lat)),
                 xlim = c(min(cluster$lon), max(cluster$lon))) +
  theme_bw()
ggsave(file = paste0(save_dir, "Clustering_map", kk, ".png"))

# mean LF in each area
LF1_cluster <- left_join(LF1, cluster) %>% rename(Flag = cell)
make.lf.cell(LF1_cluster, fcol, lcol, bins, save_dir, plot_name = paste0("NewLF", kk))
```

```{r}
teststat <- heterodist(alydens.spatial23$merges,alydens.spatial23$distseq,new_bins/1000,densmaty,
                       mmdfpdf_catch$Catch,doko=c(1,5),BB=10)
write.csv(teststat$statmat, file = "MJS distance.csv", row.names = FALSE)
# 
# teststats <- heterodists(alydens.spatial23$merges,alydens.spatial23$distseq,new_bins,densmaty,
#                          rrs,BB=c(100, 1000), bounds = c(0.005, 0.1))
```


---
title: "Fishery definition for YFT in dolphin sets"
author: "Haikun Xu"
date: "`r Sys.Date()`"
output: word_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      fig.height = 8,
                      fig.width = 12)
```

```{r load raw data and library}
library(FishFreqClustering)
library(FishFreqTree)
library(tidyverse)

directory <- "D:/OneDrive - IATTC/IATTC/2024/Irregular clustering/YFT DEL/"
setwd(directory)

Raw <- read.csv("yft_lf_2000_to_2022.csv")
Raw$quarter = ceiling(Raw$month / 3)
Raw$lat = Raw$lat.5deg + 2.5
Raw$lon = Raw$lon.5deg - 2.5
```

```{r prepare the dataset for the clustering analysis}
LF.DEL <- Raw %>% filter(class == 6, setype == 1) # 1=DEL; 4=NOA; 5=OBJ

LF <- LF.DEL[, c("year", "quarter", "lat", "lon", paste0("X", 1:201))] %>%
  group_by(lat, lon) %>%
  mutate(N = length(unique(paste0(year, "-", quarter)))) %>%
  filter(N > 3, lat > -10) # remove the cells with less than 4 quarters of data since 2000

bins <- seq(1, 201, 1) # data length bins
new_bins <- seq(61, 200, 1) # bins to be used in the clustering analysis

# first aggregate the raw LF to the new bins by quarter
LF1 <- lf.aggregate(LF, fcol = 5, lcol = 205, bins, new_bins, LengthOnly = FALSE)

# Chekcing the data by making two plots
bins <- new_bins # use the new bins
nbins <- length(bins)
fcol = 5
lcol = 4 + length(bins)
save_dir=directory

make.meanl.map(LF1, fcol, lcol, bins, save_dir, width = 10, height = 10)
make.lf.map(LF1, fcol, lcol, bins, save_dir)

# divide the LF by the mean LF for the year-quarter
LF2 <- lf.demean(LF1, fcol, lcol, bins)
```

```{r catch}
cae <- BSE::read.cae.f("D:/OneDrive - IATTC/IATTC/2024/SAC15/PS Database/", "CAE-LatLon2000-2023.txt",2000,2023)

YFT_DEL_catch <- cae %>%
  filter(setype == 1, class == 6) %>%
  rename(lat = latc5, lon = lonc5) %>%
  group_by(lat, lon) %>%
  summarise(Catch = sum(sum.trop.tunas)/1000)

wmap <- map_data("world")
ggplot(data = YFT_DEL_catch) +
  geom_tile(aes(x = lon, y = lat, fill = Catch), color = "black") +
    scale_fill_gradient(
    low = "white",
    high = "red",
    na.value = "white",
    limits = c(0, max(YFT_DEL_catch$Catch))
  ) +
  geom_polygon(
    data = wmap,
    aes(long, lat, group = group),
    fill = "black",
    colour = "white",
    lwd = 0.5
  ) +
  coord_quickmap(ylim = c(min(YFT_DEL_catch$lat), max(YFT_DEL_catch$lat)), xlim = c(min(YFT_DEL_catch$lon), max(YFT_DEL_catch$lon))) +
  theme_bw()
```

```{r}
mmd <- LF2[,c(2,4:(lcol+1))] # mmd is the input data for the clustering analysis - it should have year, lat, lon, and bin numbers

# setting up input data frames for clustering algorithm
temp = packbylatlon(mmd, 5, 5, nbins)  # aggregate the input LF across time for each grid cell

packedmmd3 = temp$table1
packedpdf3 = topdf(packedmmd3, 4, 3 + nbins)
# packedcdf3 = tocdf(packedpdf3, 4, 3 + nbins)
mmdt = packedmmd3[packedmmd3[, 4 + nbins] > 0,]
rrs = mmdt[, 4 + nbins] # sample size
mmdtpdf = packedpdf3[packedmmd3[, 4 + nbins] > 0,] # PDF sums to 1 for each grid
mmdtpdf[, 4 + nbins] = mmdt[, 4 + nbins]
# mmdtcdf = packedcdf3[packedmmd3[, 4 + nbins] > 0,]
# mmdtcdf[, 4 + nbins] = mmdt[, 4 + nbins]

names(mmdtpdf)[2:3] <- c("lat", "lon")
mmdtpdf$Number <- 1:nrow(mmdtpdf)
mmdfpdf_catch <- left_join(mmdtpdf, YFT_DEL_catch)

# check grid ID
ggplot(data = mmdfpdf_catch) +
  geom_polygon(
    data = wmap,
    aes(long, lat, group = group),
    fill = "black",
    colour = "white",
    lwd = 0.5
  ) +
  geom_text(aes(x = lon, y = lat, label = Number), color = "red", size = 5) +
  coord_quickmap(ylim = c(min(mmdfpdf_catch$lat), max(mmdfpdf_catch$lat)), xlim = c(min(mmdfpdf_catch$lon), max(mmdfpdf_catch$lon))) +
  ggtitle("Grid ID") +
  theme_bw()

densmatx = matrix(0, nrow(mmdt), 512)
densmaty = matrix(0, nrow(mmdt), 512)
for(i in 1:nrow(mmdt)) {
  weightvec = t(mmdt[i, 4:(3 + nbins)])
  weightvec = weightvec / sum(weightvec)
  tempmmd = density(seq(0.61, 2.00, 0.01), weights = weightvec, bw = 0.10)
  densmatx[i, ] = tempmmd$x
  densmaty[i, ] = tempmmd$y
}

# run distributional clustering with adjacency criterion
adjmat <- adjinf(mmdtpdf[, 2], mmdtpdf[, 3], mindist = 5 * sqrt(2)) # the matrix specifying adjacency 

alydens.spatial23 <-
  hclust.regionsmm(
    as.matrix(densmaty),
    adj = TRUE, # adjacent areas
    adjmat = adjmat,
    rr = mmdfpdf_catch$Catch # rr is the weighting factor; equal weighting is used in this case
  )

# Look at the tree structure
cplotu(alydens.spatial23$merges, alydens.spatial23$distseq, hopt = 'dist')
```

```{r 3 areas}
# making maps of the clusters and corresponding L-F density curves

#     kk is the number of clusters to use
kk = 5
# save clustering results
temp <- putcolor(alydens.spatial23$merges, kk)
cluster <- cbind(mmdt[,2:3], factor(temp-1), round(mmdfpdf_catch$Catch,0))
names(cluster) <- c("lat", "lon", "cell", "Weight")
write.csv(cluster, file = paste0(save_dir, "cluster_YFT", kk, ".csv"), row.names = FALSE)

# # map of clusters
ggplot(data = cluster) +
  geom_tile(aes(x = lon, y = lat, fill = cell), color = "black") +
  geom_polygon(
    data = wmap,
    aes(long, lat, group = group),
    fill = "black",
    colour = "white",
    lwd = 0.5
  ) +
  geom_text(aes(x = lon, y = lat, label = Weight),
            color = "white",
            size = 7,
            ) +
  coord_quickmap(ylim = c(min(cluster$lat), max(cluster$lat)), xlim = c(min(cluster$lon), max(cluster$lon))) +
  theme_bw()
ggsave(file = paste0(save_dir, "Clustering_map", kk, ".png"))

# mean LF in each area
# LF1_cluster <- left_join(LF1, cluster) %>% rename(Flag = cell)
# make.lf.cell(LF1_cluster, fcol, lcol, bins, save_dir, plot_name = paste0("NewLF", kk))

# draw density curves by cluster
colcol = rep(c(2, 3, 4, 5, 6, 7, 8), 3)
atitle.cl<-"2000-2023"
clusthistd3(kk,colseq=temp,atitle.cl,colcol,xlims = c(0,2), ylims = c(0,2.5))
```